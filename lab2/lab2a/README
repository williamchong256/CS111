NAME: William Chong
EMAIL: williamchong256@gmail.com
ID: 205114665

Question 2.1.1:
  - Why does it take many iterations before errors are seen?
	With a low number of iterations each thread is more likely to finish
	its workload and exit the critical section (incrementing the counter
	global variable) before being preempted by another thread. However
	with a higher number of iterations (greater than 1000), then each thread
	fairly consistently is in the middle of iterating the counter when it
	is preempted by another thread which causes the race condition error.
	The interrupting thread then accesses the global variable and modifies
	it, leading to erroneous counter values at the end.
  - Why does a significantly smaller number of iterations so seldom fail?
	With a significantly smaller number of iterations, each thread is 
	likely to be able to finish its iterations and exit the critical
	section before a race condition can develop.

Question 2.1.2
  - Why are the --yield runs so much slower?
	The --yield runs are slower than add-none runs because the --yield option causes
	threads to more readily, and frequently, yield their time slice to other threads.
	Since the cost of thread context switching is expensive, more frequent yields 
	by each thread means more overhead.
  - Where is the additional time going?
	The additional time is spent doing thread context switches--saving and restoring
	register values. 
  - Is it possible to get valid per-operation timings if we are using the --yield option?
    If so, explain how. If not, explain why not.
	It isn't possible to get accurate per-operation timings with the --yield option 
	because the timing being measured is including not only the actual operation,
	but is also recording the time it takes to perform the context switches, which 
	adds significant overhead that is not the actual runtime of the operations. It is
	difficult (perhaps very difficult) to get an accurate measure of the time cost
	for context switch overhead, and thus cannot get an accurate measure of the
	per-operation timing.

Question 2.1.3
  - Why does the average cost per operation drop with increasing iterations?
	The average cost per operation drops with increasing iterations because for 
	smaller numbers of iterations, the overall cost is dominated more by the 
	cost of creating and joining threads. With higher numbers of iterations,
	the cost of creating and joining threads remains constant, while the time
	to perform the workload/operations dominates the timing. Thus, the average
	cost per operation is decreased.
  - If the cost per iteration is a function of the number of iterations, how do we know how 
    many iterations to run (or what the "correct" cost is)?
	To determine the accurate cost per iteration (operation), we would run a very large
	number of iterations so that the overhead of managing threads is far outweighed
	by the actual time cost of performing the operations. As number of iterations 
	increases, the cost per operation approaches the "correct cost".

Question 2.1.4
  - Why do all of the options perform similarly for low numbers of threads?
	With low numbers of threads, there are less threads contending for the protected
	critical section. With less threads, there is less testing/checking if the lock
	is free to be acquired. Thus there is less time overhead due to waiting for a 
	resource.
  - Why do the three protected operations slow down as the number of threads rises?
	As the number of threads increases, each thread spends more time checking or
	waiting for the resource to be freed up. The increased number of thread means
	more threads attempt to acquire a lock, which leads to slow down.


